{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57343d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T21:04:33.012852Z",
     "iopub.status.busy": "2025-04-25T21:04:33.012468Z",
     "iopub.status.idle": "2025-04-25T21:04:38.850014Z",
     "shell.execute_reply": "2025-04-25T21:04:38.848771Z"
    },
    "papermill": {
     "duration": 5.844963,
     "end_time": "2025-04-25T21:04:38.852313",
     "exception": false,
     "start_time": "2025-04-25T21:04:33.007350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-generativeai tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80000a7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T21:04:38.860451Z",
     "iopub.status.busy": "2025-04-25T21:04:38.859392Z",
     "iopub.status.idle": "2025-04-25T21:04:45.331942Z",
     "shell.execute_reply": "2025-04-25T21:04:45.330913Z"
    },
    "papermill": {
     "duration": 6.478234,
     "end_time": "2025-04-25T21:04:45.333754",
     "exception": false,
     "start_time": "2025-04-25T21:04:38.855520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:623: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a prompt designed to generate exactly 5 single-word answerable questions based on a given image, covering a diverse range of question types:\n",
      "\n",
      "```\n",
      "You are an AI assistant specialized in generating image-based question-answer pairs. Your task is to generate exactly 5 questions about a given image.  The questions should be diverse, covering different aspects of the image.  Each question should have a single-word answer.  The answer *must* be verifiable by visually inspecting the image alone.  Do not use external knowledge. The questions should be simple and avoid ambiguity.  Do not use numbers as digits in your answers (e.g., use \"Three\" instead of \"3\"). Avoid questions that are subjective or open to interpretation.  Do not use proper nouns in the answers. Generate questions based on the following types (but not limited to these):\n",
      "\n",
      "*   **Object Identification:**  Focus on the most obvious object.\n",
      "*   **Color Recognition:** Identify the dominant or most prominent color.\n",
      "*   **Material Identification:** If possible, identify the most obvious material.\n",
      "*   **Shape Recognition:**  Basic shapes like \"Round,\" \"Square,\" \"Triangle.\"\n",
      "*   **Texture Identification:** Rough, Smooth, Bumpy etc.\n",
      "*   **Location/Position:** Common positions relative to the background.\n",
      "*   **Action/Activity (if applicable):** If someone or something is clearly *doing* something.\n",
      "*   **State (condition of the object):** Clean, Dirty, Broken, etc.\n",
      "*   **Size estimation:** Is the object small?\n",
      "\n",
      "Do not use the same question type more than twice. Ensure the questions are grammatical and make sense.\n",
      "\n",
      "For the provided image, generate the 5 questions. Provide the questions separated by newlines.\n",
      "```\n",
      "\n",
      "**Explanation of the Prompt and Why it Works:**\n",
      "\n",
      "*   **Clear Role Definition:** \"You are an AI assistant specialized in generating image-based question-answer pairs.\"  This sets the context for the AI.\n",
      "*   **Strict Constraints:** \"Your task is to generate *exactly* 5 questions...Each question should have a *single-word* answer.\" This is critical for achieving the desired output format.  The \"must be verifiable by visually inspecting the image alone\" clause reinforces the constraint.\n",
      "*   **Diversity Requirement:** \"The questions should be diverse, covering different aspects of the image.\" This encourages exploration of different question types, instead of generating 5 questions all about color, for instance.\n",
      "*   **Negative Constraints:** \"Do not use external knowledge... Avoid questions that are subjective or open to interpretation... Do not use numbers as digits in your answers...Avoid proper nouns in the answers.\" These prevent common failure modes and ensure the questions are answerable solely from the image.\n",
      "*   **Type Guidance:** The bulleted list provides examples of question types, helping the AI understand the desired range of questions.  The instruction \"not limited to these\" gives it some flexibility.  The limit of a maximum of two questions per type prevents over representation.\n",
      "*   **Formatting:** \"Provide the questions separated by newlines\" ensures the questions are easy to parse.\n",
      "*   **Emphasis on Simplicity and Clarity:**  Phrases like \"simple and avoid ambiguity\" guide the AI to generate questions that humans can readily understand and answer.\n",
      "\n",
      "**How to Use the Prompt:**\n",
      "\n",
      "1.  **Input the Prompt:**  Paste the above prompt into your AI model (e.g., a large language model with image understanding capabilities).\n",
      "2.  **Provide the Image:**  Make sure to give the AI model the image you want questions generated for.  The exact method will depend on the specific AI platform you're using.\n",
      "3.  **Run the Model:**  Initiate the generation process.\n",
      "4.  **Review and Refine:** While this prompt is designed to produce high-quality results, you might need to iterate on the prompt slightly based on the specific AI model you're using and the types of images you're processing.  For example, you might need to adjust the list of suggested question types or add more specific constraints.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyAFBFw2YZnI0epnpUIzHxknTDebaonKcwE\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents='''Design a prompt to generate exactly 5 questions, with a single answer per image.\n",
    "            The given answer must be of only one word.\n",
    "            For a given image, I want to to generate multiple types of questions\n",
    "            based on the dataset covering questions which one can answer just by\n",
    "            looking at the image. Make sure the answers never contain digits e.g. Three instead of 3.\n",
    "            Example:\n",
    "            What is the colour of the fruit?\n",
    "            These types can include, but are *not limited* to:\n",
    "\n",
    "            *   **Object Identification:** What is the main/prominent object in the image?\n",
    "            *   **Color Recognition:** What is the dominant color in the scene?\n",
    "            *   **Material Identification:** What is the primary material of the object?\n",
    "            *   **Shape Recognition:** What is the general shape of the object?\n",
    "            *   **Texture Identification:** What is the primary texture visible?\n",
    "            *   **Location/Position:** Where is the object placed?\n",
    "            *   **Quantity Estimation:** What is the number of the object?\n",
    "            *   **Action/Activity (if applicable):** What is the action happening?\n",
    "            *   **State (condition of the object):** Is the object broken?\n",
    "            ''',\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817c30ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T21:04:45.340886Z",
     "iopub.status.busy": "2025-04-25T21:04:45.340155Z",
     "iopub.status.idle": "2025-04-25T21:04:45.345547Z",
     "shell.execute_reply": "2025-04-25T21:04:45.344554Z"
    },
    "papermill": {
     "duration": 0.010663,
     "end_time": "2025-04-25T21:04:45.347184",
     "exception": false,
     "start_time": "2025-04-25T21:04:45.336521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_for_qa = '''\n",
    "Generate exactly 5 questions about a given image. Each question must have a single-word answer.\n",
    "The questions should cover a range of visual aspects detectable directly from the image, including, but not limited to:\n",
    "\n",
    "*   **Object Identification:** (e.g., What is the main object?)\n",
    "*   **Color Recognition:** (e.g., What color is the sky?)\n",
    "*   **Material Identification:** (e.g., What is the vase made of?)\n",
    "*   **Shape Recognition:** (e.g., What is the shape of the roof?)\n",
    "*   **Texture Identification:** (e.g., What is the texture of the sand?)\n",
    "*   **Location/Position:** (e.g., Where is the cat?)\n",
    "*   **Quantity Estimation:** (e.g., How many trees?)  (Answer must be a word, e.g., \"Three\" not \"3\")\n",
    "*   **Action/Activity (if applicable):** (e.g., What is the dog doing?)\n",
    "*   **State (condition of the object):** (e.g., Is the glass full?)\n",
    "\n",
    "The questions should not be repetitive in subject matter, and the answers should only be one word.\n",
    "Ensure no answers contain digits; instead, use the word representation of numbers (e.g., \"Four\" instead of \"4\").\n",
    "\n",
    "Here's what the desired output format should look like (but with different, relevant questions):\n",
    "\n",
    "What is the main object?\n",
    "What is the dominant color?\n",
    "What is the object's shape?\n",
    "Is the container empty?\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb032f",
   "metadata": {
    "papermill": {
     "duration": 0.002769,
     "end_time": "2025-04-25T21:04:45.352845",
     "exception": false,
     "start_time": "2025-04-25T21:04:45.350076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SQID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b808ebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T21:04:45.359858Z",
     "iopub.status.busy": "2025-04-25T21:04:45.359445Z",
     "iopub.status.idle": "2025-04-25T21:49:34.217280Z",
     "shell.execute_reply": "2025-04-25T21:49:34.215824Z"
    },
    "papermill": {
     "duration": 2688.864178,
     "end_time": "2025-04-25T21:49:34.219658",
     "exception": false,
     "start_time": "2025-04-25T21:04:45.355480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   7%|▋         | 72/984 [01:59<23:26,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] processing '/kaggle/input/sqid-test/images/B095YDVLTV.jpg': 408 Request Timeout. {'message': 'Request Timeout', 'status': 'Request Timeout'}. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  11%|█         | 110/984 [06:09<24:27,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] processing '/kaggle/input/sqid-test/images/B07RSTRD2Z.jpg': 408 Request Timeout. {'message': 'Request Timeout', 'status': 'Request Timeout'}. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  35%|███▍      | 344/984 [15:28<18:01,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] processing '/kaggle/input/sqid-test/images/B07H5L7HKS.jpg': 408 Request Timeout. {'message': 'Request Timeout', 'status': 'Request Timeout'}. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  53%|█████▎    | 524/984 [22:31<14:05,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] processing '/kaggle/input/sqid-test/images/B07SD36N44.jpg': 408 Request Timeout. {'message': 'Request Timeout', 'status': 'Request Timeout'}. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  73%|███████▎  | 717/984 [30:23<07:42,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] processing '/kaggle/input/sqid-test/images/B07N8T5QRV.jpg': 408 Request Timeout. {'message': 'Request Timeout', 'status': 'Request Timeout'}. Retrying...\n",
      "[ERROR] processing '/kaggle/input/sqid-test/images/B07N8T5QRV.jpg': 408 Request Timeout. {'message': 'Request Timeout', 'status': 'Request Timeout'}. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  75%|███████▌  | 742/984 [34:25<07:02,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] processing '/kaggle/input/sqid-test/images/B0041LNT6G.jpg': 408 Request Timeout. {'message': 'Request Timeout', 'status': 'Request Timeout'}. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 984/984 [44:45<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to SQID_test_generated_vqa.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "class QA(BaseModel):\n",
    "    questions: List[str] = Field(description='Questions about the image as per format')\n",
    "    answers: List[str] = Field(description='Single word answers')\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyAFBFw2YZnI0epnpUIzHxknTDebaonKcwE\")\n",
    "\n",
    "# Collect all .png files recursively\n",
    "filenames = []\n",
    "for dirpath, _, filenames_in_dir in os.walk('/kaggle/input/sqid-test/images'):\n",
    "    for file in filenames_in_dir:\n",
    "        if file.lower().endswith(('.jpg')):\n",
    "            filenames.append(os.path.join(dirpath, file))\n",
    "\n",
    "# Limit to first 10 for experiment\n",
    "# filenames = filenames[:10]\n",
    "\n",
    "results = []\n",
    "\n",
    "for path in tqdm(filenames, desc=\"Processing images\"):\n",
    "    while True:\n",
    "        try:\n",
    "            img = Image.open(path)\n",
    "\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=[img, prompt_for_qa],\n",
    "                config={\n",
    "                    'response_mime_type': 'application/json',\n",
    "                    'response_schema': QA,\n",
    "                }\n",
    "            )\n",
    "            data = QA.model_validate_json(response.text)\n",
    "            results.append({\n",
    "                'image_path': path,\n",
    "                'questions': \"|\".join(data.questions),  # pipe-delimited list\n",
    "                'answers':   \"|\".join(data.answers),\n",
    "            })\n",
    "\n",
    "            # success, move to next image\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            # log the error and retry\n",
    "            print(f\"[ERROR] processing {path!r}: {e}. Retrying...\")\n",
    "\n",
    "# convert to DataFrame and save CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('SQID_test_generated_vqa.csv', index=False)\n",
    "print(\"Saved results to SQID_test_generated_vqa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8956c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T21:49:34.361892Z",
     "iopub.status.busy": "2025-04-25T21:49:34.361538Z",
     "iopub.status.idle": "2025-04-25T21:49:34.409245Z",
     "shell.execute_reply": "2025-04-25T21:49:34.408110Z"
    },
    "papermill": {
     "duration": 0.1117,
     "end_time": "2025-04-25T21:49:34.410842",
     "exception": false,
     "start_time": "2025-04-25T21:49:34.299142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B01469HU8K.jpg</td>\n",
       "      <td>How many pairs?|What color above?|What shape a...</td>\n",
       "      <td>Five|Black|Rectangular|Metal|Glasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B083C6HZZX.jpg</td>\n",
       "      <td>What is the object?|What color is it?|What is ...</td>\n",
       "      <td>Bow|Black|Wood|One|Bent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B07MHMN3Y8.jpg</td>\n",
       "      <td>What are these?|How many syringes?|What color ...</td>\n",
       "      <td>Syringes|Four|Clear|Plastic|Twenty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B07GDS514N.jpg</td>\n",
       "      <td>What objects are shown?|How many boxes?|What c...</td>\n",
       "      <td>Containers|Four|Green|Plastic|Square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B083PW1CW4.jpg</td>\n",
       "      <td>Background color?|How many hands?|Is object re...</td>\n",
       "      <td>Black|One|Attached|Snap|Skeleton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B073GJY95J.jpg</td>\n",
       "      <td>What are those?|What color is?|How many are?|W...</td>\n",
       "      <td>Mittens|White|Nine|Fabric|Rounded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B07WJYY49P.jpg</td>\n",
       "      <td>What object is this?|What color is camera?|Wha...</td>\n",
       "      <td>Camera|Black|Circular|Canon|One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B0922R4YL2.jpg</td>\n",
       "      <td>What object stands tallest?|What is the ocean'...</td>\n",
       "      <td>Lighthouse|Blue|White|One|Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B071GXMM2R.jpg</td>\n",
       "      <td>What is depicted?|What color are bags?|How man...</td>\n",
       "      <td>Bags|Black|Three|Paper|Vertical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>/kaggle/input/sqid-test/images/B08FLZNYGB.jpg</td>\n",
       "      <td>What word is repeated?|What is the emblem colo...</td>\n",
       "      <td>Tundra|Black|Two|Rectangular|Letters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        image_path  \\\n",
       "0    /kaggle/input/sqid-test/images/B01469HU8K.jpg   \n",
       "1    /kaggle/input/sqid-test/images/B083C6HZZX.jpg   \n",
       "2    /kaggle/input/sqid-test/images/B07MHMN3Y8.jpg   \n",
       "3    /kaggle/input/sqid-test/images/B07GDS514N.jpg   \n",
       "4    /kaggle/input/sqid-test/images/B083PW1CW4.jpg   \n",
       "..                                             ...   \n",
       "979  /kaggle/input/sqid-test/images/B073GJY95J.jpg   \n",
       "980  /kaggle/input/sqid-test/images/B07WJYY49P.jpg   \n",
       "981  /kaggle/input/sqid-test/images/B0922R4YL2.jpg   \n",
       "982  /kaggle/input/sqid-test/images/B071GXMM2R.jpg   \n",
       "983  /kaggle/input/sqid-test/images/B08FLZNYGB.jpg   \n",
       "\n",
       "                                             questions  \\\n",
       "0    How many pairs?|What color above?|What shape a...   \n",
       "1    What is the object?|What color is it?|What is ...   \n",
       "2    What are these?|How many syringes?|What color ...   \n",
       "3    What objects are shown?|How many boxes?|What c...   \n",
       "4    Background color?|How many hands?|Is object re...   \n",
       "..                                                 ...   \n",
       "979  What are those?|What color is?|How many are?|W...   \n",
       "980  What object is this?|What color is camera?|Wha...   \n",
       "981  What object stands tallest?|What is the ocean'...   \n",
       "982  What is depicted?|What color are bags?|How man...   \n",
       "983  What word is repeated?|What is the emblem colo...   \n",
       "\n",
       "                                  answers  \n",
       "0    Five|Black|Rectangular|Metal|Glasses  \n",
       "1                 Bow|Black|Wood|One|Bent  \n",
       "2      Syringes|Four|Clear|Plastic|Twenty  \n",
       "3    Containers|Four|Green|Plastic|Square  \n",
       "4        Black|One|Attached|Snap|Skeleton  \n",
       "..                                    ...  \n",
       "979     Mittens|White|Nine|Fabric|Rounded  \n",
       "980       Camera|Black|Circular|Canon|One  \n",
       "981     Lighthouse|Blue|White|One|Reading  \n",
       "982       Bags|Black|Three|Paper|Vertical  \n",
       "983  Tundra|Black|Two|Rectangular|Letters  \n",
       "\n",
       "[984 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/working/SQID_test_generated_vqa.csv')\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8659dce",
   "metadata": {
    "papermill": {
     "duration": 0.050608,
     "end_time": "2025-04-25T21:49:34.512253",
     "exception": false,
     "start_time": "2025-04-25T21:49:34.461645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7253090,
     "sourceId": 11568552,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2708.154755,
   "end_time": "2025-04-25T21:49:35.588561",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-25T21:04:27.433806",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
