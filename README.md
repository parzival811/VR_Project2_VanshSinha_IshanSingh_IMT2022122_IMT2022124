# Multimodal VQA with ABO Dataset

This repository contains all scripts, notebooks and datasets used for the AIM825 Mini Project 2 on Multimodal Visual Question Answering (VQA) with Amazon Berkeley Objects (ABO) dataset.

## ğŸ‘¥ Team Members

* **Vansh Sinha** â€“ IMT2022122
* **Ishan Singh** â€“ IMT2022124

## ğŸ“„ Report
- `Report.pdf` â€“ Final project report detailing data curation, model selection, fine-tuning, evaluation, and results.

## ğŸ“‚ CuratedDatasets

### â””â”€â”€ CuratedDatasetForEvaluations
- `SQID_test_generated_vqa.csv` â€“ VQA dataset generated from Shopping Queries Image Dataset (SQID) for evaluating baseline and fine-tuned model performance.

### â””â”€â”€ CuratedDatasetForFineTuning
- `RO_generated_vqa.csv` â€“ VQA dataset curated from ABO dataset using Random Oversampling strategy for fine-tuning.
- `S_generated_vqa.csv` â€“ VQA dataset curated from ABO dataset using Custom Sampling strategy for fine-tuning.

## ğŸ“‚ InferenceScript
- `inference.py` â€“ Script to load final fine-tuned model and generate predictions on new input.
- `requirements.txt` â€“ Python dependencies needed to run the inference script.

## ğŸ“‚ Notebooks

### ğŸ›  Dataset Curation
- `vrmp2-dataset-curation-1.ipynb` â€“ Initial ABO dataset preprocessing and sampling images based on 2 different sampling strategies.
- `vrmp2-dataset-curation-2a.ipynb` â€“ VQA dataset generation using Random Oversampling.
- `vrmp2-dataset-curation-2b.ipynb` â€“ VQA dataset generation using Custom Sampling.
- `vrmp2-sqid-test-dataset-preprocessing.ipynb` â€“ SQID test dataset download and preprocessing.
- `vrmp2-sqid-test-dataset-curation.ipynb` â€“ VQA dataset generation using SQID test dataset.

### ğŸ§  Baseline Evaluation
- `vrmp2-blip-baseline.ipynb` â€“ BLIP model baseline evaluation.
- `vrmp2-paligemma-baseline.ipynb` â€“ PaliGemma model baseline evaluation.
- `vrmp2-vilt-baseline.ipynb` â€“ VILT model baseline evaluation.
- `vrmp2-baseline-evaluations.ipynb` â€“ Summarizes and compares metrics across all baseline models.

### ğŸ§ª Fine-Tuning and Evaluations

#### ğŸ” Random Oversampled VQA Dataset
- `vrmp2-ro-blip-lora-finetuning.ipynb` â€“ BLIP fine-tuning using LoRA.
- `vrmp2-ro-blip-finetuned-predictions.ipynb` â€“ Predictions from fine-tuned BLIP.
- `vrmp2-ro-paligemma-lora-finetuning.ipynb` â€“ PaliGemma fine-tuning using LoRA.
- `vrmp2-ro-paligemma-finetuned-predictions.ipynb` â€“ Predictions from fine-tuned PaliGemma.
- `vrmp2-ro-finetuned-evaluations.ipynb` â€“ Evaluation of models fine-tuned on Random Oversampled dataset.

#### ğŸ” Custom Sampled VQA Dataset
- `vrmp2-s-blip-lora-finetuning.ipynb` â€“ BLIP fine-tuning using LoRA.
- `vrmp2-s-blip-finetuned-predictions.ipynb` â€“ Predictions from fine-tuned BLIP.
- `vrmp2-s-paligemma-lora-finetuning.ipynb` â€“ PaliGemma fine-tuning using LoRA.
- `vrmp2-s-paligemma-finetuned-predictions.ipynb` â€“ Predictions from fine-tuned PaliGemma.
- `vrmp2-s-finetuned-evaluations.ipynb` â€“ Evaluation of models fine-tuned on Custom Sampled dataset.

